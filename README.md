The objective of this course is to evaluate the influence of ``preprocessing`` in NLP by first focusing on text classification and a classical Machine Learning Pipeline.

This repository contains :

- Slides in PDF : `Pre_processing.pdf`
- A simple notebook to quickly compare different pre-processing techniques:
  - `01_run_experiments_simple_single_task.ipynb` (Kaggle dataset)
- Another example with a multilingual task (using `corpus_muli.zip`):
  - 01_DiagLang.ipynb
- Now it's up to you to find the best pre-processing configuration with another multilingual dataset:
  - https://www.kaggle.com/datasets/suraj520/multi-task-learning
- You can next vary the classification models (ML, language models) with differ preprocessing configurations in order to find :
  - What preprocessing combinations work best
  - How much this depends on the learning method 
