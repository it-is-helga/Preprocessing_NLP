{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b262b75c",
   "metadata": {},
   "source": [
    "# NLP Lab â€“ Minimal Preprocessing Experiments (Single Task)\n",
    "\n",
    "This notebook runs a tiny grid of preprocessing experiments on **one** supervised text classification task\n",
    "and saves results to `results_single_task.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96259f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aad0a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "OUTFILE = Path(\"results_single_task_3_classes.csv\")\n",
    "\n",
    "macro_f1 = make_scorer(f1_score, average=\"macro\")\n",
    "SCORING = {\"acc\": \"accuracy\", \"macro_f1\": macro_f1}\n",
    "\n",
    "def mean_scores(scores):\n",
    "    return {k.replace(\"test_\", \"\"): float(np.mean(v))\n",
    "            for k, v in scores.items() if k.startswith(\"test_\")}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45b8320f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stopwordsiso in /home/ceres/anaconda3/lib/python3.10/site-packages (0.6.1)\n",
      "Prep: DON\n",
      "I am travelling to Nancy for an NLP course at IDMC :https://idmc.univ-lorraine.fr/\n",
      "Prep: LOW\n",
      "i am travelling to nancy for an nlp course at idmc :https://idmc.univ-lorraine.fr/\n",
      "Prep: URLrem\n",
      "I am travelling to Nancy for an NLP course at IDMC : \n",
      "Prep: URLrep\n",
      "I am travelling to Nancy for an NLP course at IDMC : <URL> \n",
      "Prep: PUN\n",
      "I am travelling to Nancy for an NLP course at IDMC  https   idmc univ lorraine fr \n",
      "Prep: RSW\n",
      "I travelling Nancy NLP IDMC : https : / / idmc . univ - lorraine . /\n",
      "Prep: LOW+URLrem\n",
      "i am travelling to nancy for an nlp course at idmc :\n",
      "Prep: LOW+URLrep\n",
      "i am travelling to nancy for an nlp course at idmc : <URL>\n",
      "Prep: LOW+PUN\n",
      "i am travelling to nancy for an nlp course at idmc https idmc univ lorraine fr\n",
      "Prep: LOW+URLrem+PUN\n",
      "i am travelling to nancy for an nlp course at idmc\n",
      "Prep: LOW+URLrep+PUN\n",
      "i am travelling to nancy for an nlp course at idmc\n",
      "Prep: LOW+URLrem+PUN+RSW\n",
      "travelling nancy nlp idmc\n",
      "Prep: LOW+URLrep+PUN+RSW\n",
      "travelling nancy nlp idmc URL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ceres/anaconda3/lib/python3.10/site-packages/stopwordsiso/_core.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "# --- Preprocessing (kept simple) ---\n",
    "\n",
    "!pip install stopwordsiso\n",
    "import stopwordsiso\n",
    "\n",
    "def don(text): \n",
    "    return text\n",
    "    \n",
    "def lower(text): \n",
    "    return text.lower()\n",
    "\n",
    "URL_RE = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "def remove_urls(text): \n",
    "    return URL_RE.sub(\" \", text)\n",
    "    \n",
    "def replace_urls(text): \n",
    "    return URL_RE.sub(\" <URL> \", text)\n",
    "    \n",
    "PUNCT_RE = re.compile(r\"[^\\w\\s]\")\n",
    "def remove_punct(text): \n",
    "    return PUNCT_RE.sub(\" \", text)\n",
    "\n",
    "TOKEN_PUNC = re.compile(r\"\\w+|[^\\w\\s]\")\n",
    "def remove_stopwords(text):\n",
    "    #very slow but keeps punctuation\n",
    "    \n",
    "    return \" \".join([T for T in TOKEN_PUNC.findall(text) if T not in set(stopwordsiso.stopwords(\"en\"))])\n",
    "\n",
    "    \n",
    "def compose(*funcs):\n",
    "    def f(text):\n",
    "        for fn in funcs:\n",
    "            text = fn(text)\n",
    "        return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return f\n",
    "\n",
    "PREPROCESSORS = {\n",
    "    \"DON\": don,\n",
    "    \"LOW\": lower,\n",
    "    \"URLrem\": remove_urls,\n",
    "    \"URLrep\": replace_urls,\n",
    "    \"PUN\": remove_punct,\n",
    "    \"RSW\": remove_stopwords,\n",
    "    \"LOW+URLrem\": compose(lower, remove_urls),\n",
    "    \"LOW+URLrep\": compose(lower, replace_urls),\n",
    "    \"LOW+PUN\": compose(lower, remove_punct),\n",
    "    \"LOW+URLrem+PUN\": compose(lower, remove_urls, remove_punct),\n",
    "    \"LOW+URLrep+PUN\": compose(lower, remove_urls, remove_punct),\n",
    "    \"LOW+URLrem+PUN+RSW\": compose(lower, remove_urls, remove_punct, remove_stopwords),\n",
    "    \"LOW+URLrep+PUN+RSW\": compose(lower, replace_urls, remove_punct, remove_stopwords),\n",
    "\n",
    "}\n",
    "toto = \"I am travelling to Nancy for an NLP course at IDMC :https://idmc.univ-lorraine.fr/\" \n",
    "for prep_name, prep in PREPROCESSORS.items():\n",
    "    print(f\"Prep: {prep_name}\")\n",
    "    print(prep(toto))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f18f0c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "\n",
      "Samples: 2950 Classes: {0, 1, 2} Labels: ['comp.graphics', 'sci.med', 'sci.space']\n"
     ]
    }
   ],
   "source": [
    "# 20 news groups to test, 3 will be enough for our purpose\n",
    "# ref : https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "print(list(newsgroups_train.target_names))\n",
    "print(\"\")\n",
    "cats = [\"comp.graphics\", \"sci.space\",\"sci.med\"]\n",
    "data = fetch_20newsgroups(\n",
    "    subset=\"all\",\n",
    "    categories=cats,\n",
    "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
    ")\n",
    "X, y = data.data, data.target\n",
    "print(\"Samples:\", len(X), \"Classes:\", set(y), \"Labels:\", data.target_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35a0118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = LogisticRegression(max_iter=2000, random_state=SEED)\n",
    "\n",
    "def evaluate(X, y, preprocess, vectorizer):\n",
    "    Xp = [preprocess(t) for t in X]\n",
    "    pipe = Pipeline([\n",
    "        (\"vect\", vectorizer),\n",
    "        (\"clf\", MODEL),\n",
    "    ])\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    scores = cross_validate(pipe, Xp, y, cv=cv, scoring=SCORING, n_jobs=-1)\n",
    "    return mean_scores(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4af70d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prep: DON          | Vec: count_word_1-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ceres/anaconda3/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/ceres/anaconda3/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/ceres/anaconda3/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/ceres/anaconda3/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/ceres/anaconda3/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.8522033898305084, 'macro_f1': 0.852437380580561}\n",
      "Prep: DON          | Vec: tfidf_word_1-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ceres/anaconda3/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/ceres/anaconda3/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/ceres/anaconda3/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/ceres/anaconda3/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/ceres/anaconda3/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.8884745762711864, 'macro_f1': 0.8887987585640236}\n",
      "Prep: DON          | Vec: count_char_3-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ceres/anaconda3/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/ceres/anaconda3/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/ceres/anaconda3/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/ceres/anaconda3/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/ceres/anaconda3/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "\n",
    "VECTORIZERS = {\n",
    "    \"count_word_1-1\": CountVectorizer(analyzer=\"word\", ngram_range=(1, 1), lowercase=False),\n",
    "    #\"count_word_1-2\": CountVectorizer(analyzer=\"word\", ngram_range=(1, 2), lowercase=False),\n",
    "    \"tfidf_word_1-1\": TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 1), lowercase=False),\n",
    "    #\"tfidf_word_1-2\": TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 2), lowercase=False),\n",
    "    \"count_char_3-5\": CountVectorizer(analyzer=\"char\", ngram_range=(3, 5), lowercase=False),\n",
    "    #\"count_charwb_3-5\": CountVectorizer(analyzer=\"char_wb\", ngram_range=(3, 5), lowercase=False),\n",
    "    \"tfidf_char_3-5\": TfidfVectorizer(analyzer=\"char\", ngram_range=(3, 5), lowercase=False),\n",
    "    #\"tfidf_charwb_3-5\": TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(3, 5), lowercase=False),\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for prep_name, prep in PREPROCESSORS.items():\n",
    "    for vec_name, vec in VECTORIZERS.items():\n",
    "        print(f\"Prep: {prep_name:12s} | Vec: {vec_name}\")\n",
    "        res = evaluate(X, y, prep, vec)\n",
    "        print(res)\n",
    "        rows.append({\n",
    "            \"preprocessing\": prep_name,\n",
    "            \"vectorizer\": vec_name,\n",
    "            **res\n",
    "        })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d0203-210d-4471-928c-4064db7d2d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows).sort_values(\"macro_f1\", ascending=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4790cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(OUTFILE, index=False)\n",
    "print(f\"Saved to: {OUTFILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24da9072-5156-40fa-9fda-c4c3048f8391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ac99a6-74fe-44d7-b7b3-2cf8ae2636cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = fetch_20newsgroups(\n",
    "    subset=\"all\",\n",
    "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
    ")\n",
    "X, y = full_data.data, full_data.target\n",
    "print(\"Samples:\", len(X), \"Classes:\", set(y), \"Labels:\", full_data.target_names)\n",
    "\n",
    "VECTORIZERS = {\n",
    "    #\"count_word_1-1\": CountVectorizer(analyzer=\"word\", ngram_range=(1, 1), lowercase=False),\n",
    "    #\"count_word_1-2\": CountVectorizer(analyzer=\"word\", ngram_range=(1, 2), lowercase=False),\n",
    "    \"tfidf_word_1-1\": TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 1), lowercase=False),\n",
    "    #\"tfidf_word_1-2\": TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 2), lowercase=False),\n",
    "    #\"count_char_3-5\": CountVectorizer(analyzer=\"char\", ngram_range=(3, 5), lowercase=False),\n",
    "    #\"count_charwb_3-5\": CountVectorizer(analyzer=\"char_wb\", ngram_range=(3, 5), lowercase=False),\n",
    "    \"tfidf_char_3-5\": TfidfVectorizer(analyzer=\"char\", ngram_range=(3, 5), lowercase=False),\n",
    "    #\"tfidf_charwb_3-5\": TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(3, 5), lowercase=False),\n",
    "}\n",
    "\n",
    "rows_full = []\n",
    "for prep_name, prep in PREPROCESSORS.items():\n",
    "    for vec_name, vec in VECTORIZERS.items():\n",
    "        print(f\"Prep: {prep_name:12s} | Vec: {vec_name}\")\n",
    "        res = evaluate(X, y, prep, vec)\n",
    "        print(res)\n",
    "        rows_full.append({\n",
    "            \"preprocessing\": prep_name,\n",
    "            \"vectorizer\": vec_name,\n",
    "            **res\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a3cb66-2ec4-45c7-96da-5926c19501c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows_full).sort_values(\"macro_f1\", ascending=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8ebb05-c365-450d-8574-ffb44f56d5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
